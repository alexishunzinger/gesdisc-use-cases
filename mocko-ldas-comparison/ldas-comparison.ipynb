{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fce52ac-a195-40be-bd21-a34a221e33a2",
   "metadata": {},
   "source": [
    "# LDAS Cloud Use Case\n",
    "\n",
    "## Demonstrate differences in soil moisture between LDAS model output and CYGNSS satellite retrievals in the Earthdata Cloud\n",
    "\n",
    "### Audience\n",
    "Soil moisture researchers who want to see differences between model- and satellite-based products\n",
    "\n",
    "### Goal\n",
    "Compare soil moisture from LDAS (NLDAS, GLDAS models) and CYGNSS (satellite retrieval) in different regions of the world (Southern Great Plains, East Africa) using in-region Earthdata Cloud access.\n",
    "\n",
    "### Assumptions\n",
    "- A variable of interest is identified\n",
    "- Data collections of interest are identified\n",
    "- User has procured access to computing resources in the AWS us-west-2 region\n",
    "\n",
    "### Preconditions\n",
    "- User has access to computing resources in the AWS us-west-2 region\n",
    "- LDAS and CYGNSS data collections are available in the Earthdata Cloud\n",
    "- Identify area(s) of interest for area-averaging\n",
    "    - Southern Great Plains: 100-95 W and 32-37 N\n",
    "    - East Africa: 43-48 E and 5-10 N  \n",
    "\n",
    "<p></p>\n",
    "\n",
    "<div style=\"background:#fc9090;border:1px solid #cccccc;padding:5px 10px;\"><big><b>Note:  </b>Because this notebook uses the S3 protocol, <em><strong>it will only run in an environment with <a href=\"https://disc.gsfc.nasa.gov/information/glossary?keywords=%22earthdata%20cloud%22&amp;title=AWS%20region\">us-west-2 AWS access</a></strong></em>.</big></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37296464-aa82-4451-90e7-056f94eb9577",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook was written using Python 3.8, and requires these libraries and files:\n",
    "- xarray\n",
    "- cartopy\n",
    "- matplotlib\n",
    "- S3FS\n",
    "  - S3FS documentation: (https://s3fs.readthedocs.io/en/latest/install.html)\n",
    "- netrc file with valid Earthdata Login credentials\n",
    "- Approval to access the GES DISC archives with your Earthdata credentials (https://disc.gsfc.nasa.gov/earthdata-login)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6955fd-4259-40a4-8154-6f3fd9853f60",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5252bf84-87bd-4940-98ca-c41ec95c3931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from netrc import netrc\n",
    "from subprocess import Popen\n",
    "from platform import system\n",
    "from getpass import getpass\n",
    "import os\n",
    "import requests\n",
    "import xarray as xr\n",
    "import s3fs\n",
    "from scipy.interpolate import griddata\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a66c8-90df-42a5-9da3-841bd0c28ca4",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "\n",
    "Two credentials are required for in-cloud direct S3 access of Earthdata:\n",
    " - Earthdata Login username and password\n",
    " - Temporary S3 access credential for NASA DAAC archives\n",
    "\n",
    "The S3 credential is generated by a lambda function that uses the Earthdata Login credentials provided in your <code>.netrc</code> file to create an access key ID, secret access key, and session token for accessing GES DISC S3 buckets. **This token will only last for one hour**, and if time expires, the kernel will need to be reset and the following cell run again. This notebook also accesses data archived by PO.DAAC. You will also need to generate S3 credentials for PO.DAAC.\n",
    "\n",
    "### STOP: Do you have your Earthdata Login credentials stored in the root directory of this compute system?\n",
    "\n",
    "If no, run the below cell to store your Earthdata username and password in a <code>.netrc</code> file.\n",
    "    \n",
    "If yes, proceed to the next cell.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf0735d-63d8-4340-9138-75d9e525ba59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## You may skip this cell if you have already stored your Earthdata Login credentials\n",
    "\n",
    "urs = 'urs.earthdata.nasa.gov'    # Earthdata URL endpoint for authentication\n",
    "prompts = ['Enter NASA Earthdata Login Username: ',\n",
    "           'Enter NASA Earthdata Login Password: ']\n",
    "\n",
    "netrc_name = \".netrc\"\n",
    "\n",
    "# Determine if netrc file exists, and if so, if it includes NASA Earthdata Login Credentials\n",
    "try:\n",
    "    netrcDir = os.path.expanduser(f\"~/{netrc_name}\")\n",
    "    netrc(netrcDir).authenticators(urs)[0]\n",
    "\n",
    "# Below, create a netrc file and prompt user for NASA Earthdata Login Username and Password\n",
    "except FileNotFoundError:\n",
    "    homeDir = os.path.expanduser(\"~\")\n",
    "    Popen('touch {0}{2} | echo machine {1} >> {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n",
    "    Popen('echo login {} >> {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    Popen('echo \\'password {} \\'>> {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    # Set restrictive permissions\n",
    "    Popen('chmod 0600 {0}{1}'.format(homeDir + os.sep, netrc_name), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b2db32-90c1-46c4-95a8-d8bb0a1ab33c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gesdisc_s3 = \"https://data.gesdisc.earthdata.nasa.gov/s3credentials\"\n",
    "podaac_s3 = \"https://archive.podaac.earthdata.nasa.gov/s3credentials\"\n",
    "\n",
    "# Define a function for S3 access credentials\n",
    "def begin_s3_direct_access(url: str=gesdisc_s3):\n",
    "    response = requests.get(url).json()\n",
    "    return s3fs.S3FileSystem(key=response['accessKeyId'],\n",
    "                             secret=response['secretAccessKey'],\n",
    "                             token=response['sessionToken'],\n",
    "                             client_kwargs={'region_name':'us-west-2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a16cb-bdc1-4a49-b084-54fb3a38a742",
   "metadata": {},
   "source": [
    "## Find Data\n",
    "\n",
    "Use the CMR API to search for the data collections of interest in the desired time range and create a list of S3 URLs that will be accessed. \n",
    "\n",
    "### Date Range\n",
    "\n",
    "- 01 June 2018 - 10 October 2018\n",
    "\n",
    "### Region\n",
    "\n",
    "- Southern Great Plains (100-95 W and 32-37 N)\n",
    "\n",
    "### Data Collections and Variables\n",
    "| Longname    | Shortname | Variable | CMR Concept ID | Time Resolution | Spatial Resolution |\n",
    "| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |\n",
    "| [NLDAS Noah Land Surface Model L4 Hourly 0.125 x 0.125 degree V2.0](https://disc.gsfc.nasa.gov/datasets/NLDAS_NOAH0125_H_2.0/summary?keywords=NLDAS_NOAH0125_H) | NLDAS_NOAH0125_H | SoilM_0_10cm | C2069246977-GES_DISC | Hourly | 0.125 deg |\n",
    "| [GLDAS Noah Land Surface Model L4 3 hourly 0.25 x 0.25 degree V2.1](https://disc.gsfc.nasa.gov/datasets/GLDAS_NOAH025_3H_2.1/summary?keywords=GLDAS_NOAH025_3H_2.1) | GLDAS_NOAH025_3H | SoilMoi0_10cm_inst | C1342986035-GES_DISC | 3-Hourly | 0.25 deg | \n",
    "| [UCAR-CU CYGNSS Level 3 Soil Moisture Version 1.0](https://podaac.jpl.nasa.gov/dataset/CYGNSS_L3_SOIL_MOISTURE_V1.0) | CYGNSS_L3_SOIL_MOISTURE_V1.0 | SM_daily | C2205122332-POCLOUD | Daily | ~0.37 deg lon. by ~0.30 deg lat. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523d74c4-8d01-4165-b194-722913ef01af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function for CMR catalog requests\n",
    "def cmr_request(params):\n",
    "    response = requests.get(url,\n",
    "                        params=params,\n",
    "                        headers={\n",
    "                            'Accept': 'application/json',\n",
    "                        }\n",
    "                       )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce94ada-1746-49ed-9f13-56daf797cbcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://cmr.earthdata.nasa.gov/search/granules'\n",
    "start_time = '2018-06-01T00:00:00Z'\n",
    "end_time = '2018-07-01T00:00:00Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3c41c-8510-4d4a-9e78-884029db8be4",
   "metadata": {},
   "source": [
    "### NLDAS hourly granules \n",
    "\n",
    "Use the table above to fill in the concept ID for the NLDAS data collection in the CMR API call. Create a list of S3 URLs based on the CMR response for your search. \n",
    "\n",
    "Estimate the number of granules you expect to find based on the time resolution and time range and adjust the page size accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "494275f0-7f16-438f-b6e5-43777b694140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nldas_concept_id = 'C2069246977-GES_DISC'\n",
    "page_size = 24*30+1\n",
    "response = cmr_request({\n",
    "                        'concept_id': nldas_concept_id,\n",
    "                        'temporal': start_time+','+end_time,\n",
    "                        'page_size': page_size\n",
    "                        })\n",
    "nldas_granules = response.json()['feed']['entry']\n",
    "\n",
    "nldas_s3_urls = []\n",
    "for granule in nldas_granules:\n",
    "    nldas_s3_urls.append(next((item['href'] for item in granule['links'] if item[\"href\"].startswith(\"s3://\")), None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec1ab7d-5995-43fd-a420-924a2aacd2df",
   "metadata": {},
   "source": [
    "### GLDAS 3-hourly granules \n",
    "\n",
    "Use the table above to fill in the concept ID for the GLDAS data collection in the CMR API call. Create a list of S3 URLs based on the CMR response for your search. \n",
    "\n",
    "Estimate the number of granules you expect to find based on the time resolution and time range and adjust the page size accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0d0d69e-9774-42fe-9b5c-6da3f46073ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gldas_concept_id = 'C1342986035-GES_DISC'\n",
    "page_size = 8*30+1\n",
    "response = cmr_request({\n",
    "                        'concept_id': gldas_concept_id,\n",
    "                        'temporal': start_time+','+end_time,\n",
    "                        'page_size': page_size\n",
    "                        })\n",
    "gldas_granules = response.json()['feed']['entry']\n",
    "\n",
    "gldas_s3_urls = []\n",
    "for granule in gldas_granules:\n",
    "    gldas_s3_urls.append(next((item['href'] for item in granule['links'] if item[\"href\"].startswith(\"s3://\")), None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93260cf1-85ff-4ec4-b7b4-c04d04245da2",
   "metadata": {},
   "source": [
    "### CYGNSS daily granules \n",
    "\n",
    "Use the table above to fill in the concept ID for the CYGNSS data collection in the CMR API call. Create a list of S3 URLs based on the CMR response for your search. \n",
    "\n",
    "Estimate the number of granules you expect to find based on the time resolution and time range and adjust the page size accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5099777f-8314-4b8c-9e24-22db9ae55588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cygnss_concept_id = 'C2205122332-POCLOUD'\n",
    "page_size = 31\n",
    "response = cmr_request({\n",
    "                        'concept_id': cygnss_concept_id,\n",
    "                        'temporal': start_time+','+end_time,\n",
    "                        'page_size': page_size\n",
    "                        })\n",
    "cygnss_granules = response.json()['feed']['entry']\n",
    "\n",
    "cygnss_s3_urls = []\n",
    "for granule in cygnss_granules:\n",
    "    cygnss_s3_urls.append(next((item['href'] for item in granule['links'] if item[\"href\"].startswith(\"s3://\") and item[\"href\"].endswith(\".nc\")), None)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c6225-12bd-412e-8907-270b2b74da9c",
   "metadata": {},
   "source": [
    "## Access Data\n",
    "\n",
    "### Begin S3FS sessions\n",
    "\n",
    "Begin your S3FS session that you set up earlier in the \"Credentials\" section.\n",
    "\n",
    "Remember, these S3FS sessions are specific to the DAAC-owned S3 buckets, so we will create a session for each DAAC we are accessing data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33e134ff-975f-4bbf-bac9-1dda1b9e1623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(s3fs.core.S3FileSystem, s3fs.core.S3FileSystem)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_gesdisc = begin_s3_direct_access(gesdisc_s3)\n",
    "fs_podaac = begin_s3_direct_access(podaac_s3)\n",
    "\n",
    "# Check that the file system is intact as an S3FileSystem object, which means that token is valid\n",
    "# Common causes of rejected S3 access tokens include incorrect passwords stored in the netrc file, or a non-existent netrc file\n",
    "type(fs_gesdisc), type(fs_podaac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6556eb2-31d9-4377-9292-ab4ea547bdc8",
   "metadata": {},
   "source": [
    "### Open granules using xarray\n",
    "\n",
    "We will use the xarray Python library to read and open the files we found using the CMR API and put into lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a844aa47-443d-48b8-ba6b-282308c6f68c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.4 s, sys: 5.29 s, total: 53.7 s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nldas_ds = xr.open_mfdataset(\n",
    "    paths=[fs_gesdisc.open(f) for f in nldas_s3_urls[0:72]],\n",
    "    combine='by_coords',\n",
    "    decode_cf=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd12dd9f-4273-4cc0-98df-fdd98d42dbab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 s, sys: 193 ms, total: 19.1 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gldas_ds = xr.open_mfdataset(\n",
    "    paths=[fs_gesdisc.open(f) for f in gldas_s3_urls[0:24]],\n",
    "    combine='by_coords',\n",
    "    mask_and_scale=True,\n",
    "    decode_cf=True,\n",
    "    parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a36180e5-da90-4a95-a590-697e9d298ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 209 ms, total: 1.55 s\n",
      "Wall time: 5.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cygnss_ds = xr.open_mfdataset(\n",
    "    paths=[fs_podaac.open(f) for f in cygnss_s3_urls[0:3]],\n",
    "    combine='by_coords',\n",
    "    mask_and_scale=True,\n",
    "    decode_cf=True,\n",
    "    parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae1439-4d88-4132-9d0f-f296b6d40cbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process Data\n",
    "\n",
    "- Match temporal resolution\n",
    "- Re-grid/interpolate to same spatial resolution\n",
    "- Create new dataset with interpolated variables\n",
    "    - Ensure same units\n",
    "- Subset with the bounding box for desired region\n",
    "- Remove the data gaps using a mask for CYGNSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeadaad-5975-4be5-af39-1d9f8cad91bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Match temporal resolution\n",
    "Resample NLDAS and GLDAS to daily time resolution to match CYGNSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "042cac3f-e04b-4883-9856-1f5fd2b29828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nldas_ds_daily = nldas_ds.resample(time=\"1D\").mean()\n",
    "gldas_ds_daily = gldas_ds.resample(time=\"1D\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be6aa3-9528-44c0-8079-75766b781680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### Re-grid to same spatial resolution\n",
    "\n",
    "Interpolate NLDAS/GLDAS to the CYGNSS grid\n",
    "\n",
    "%%time\n",
    "# NLDAS --> CYGNSS interpolation\n",
    "nx, ny = np.meshgrid(nldas_ds_daily.lon.values, nldas_ds_daily.lat.values)\n",
    "nldas_pts = np.stack([nx.ravel(), ny.ravel()], axis=1)\n",
    "\n",
    "cx, cy = cygnss_ds.longitude[0,:,:].values, cygnss_ds.latitude[0,:,:].values\n",
    "cygnss_pts = np.stack([cx.ravel(), cy.ravel()], axis=1)\n",
    "\n",
    "nldas_sm_interp = griddata(nldas_pts, nldas_ds_daily.SoilM_0_10cm.isel(time=0).values.flatten(), cygnss_pts, method='linear')\n",
    "\n",
    "nldas_sm_interp = nldas_sm_interp.reshape(252, 802)\n",
    "nldas_sm_interp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183f6c8-74e1-4470-9873-c37ac888a645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "# GLDAS --> CYGNSS interpolation\n",
    "nx, ny = np.meshgrid(gldas_ds_daily.lon.values, gldas_ds_daily.lat.values)\n",
    "gldas_pts = np.stack([nx.ravel(), ny.ravel()], axis=1)\n",
    "\n",
    "cx, cy = cygnss_ds.longitude.values, cygnss_ds.latitude.values\n",
    "cygnss_pts = np.stack([cx.ravel(), cy.ravel()], axis=1)\n",
    "\n",
    "gldas_sm_interp = griddata(gldas_pts, gldas_ds_daily.SoilMoi0_10cm_inst[0,:,:].values.flatten(), cygnss_pts, method='linear')\n",
    "\n",
    "gldas_sm_interp = gldas_sm_interp.reshape(1, 252, 802)\n",
    "#gldas_sm_interp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cfe652-6b1a-49d7-b0e8-11b34f7d860d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Add interpolated variables to a new dataset\n",
    "\n",
    "Add interpolated variables to CYGNSS dataset and convert units\n",
    "\n",
    "\n",
    "Divide NLDAS and GLDAS by 100.0 to convert from [kg m-2] to [m^3 m-3].\n",
    "\n",
    "\n",
    "CYGNSS is in [cm^3 cm-3], which is identical to [m^3 m-3].\n",
    "\n",
    "cygnss_ds = cygnss_ds.assign(NLDAS_SoilM_0_10cm=([\"time\", \"lat\", \"lon\"], nldas_sm_interp/100))\n",
    "cygnss_ds.NLDAS_SoilM_0_10cm\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94683886-19b3-4ed0-85cd-5e04b5b0eec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cygnss_ds = cygnss_ds.assign(GLDAS_SoilMoi0_10cm_inst=([\"time\", \"lat\", \"lon\"], gldas_sm_interp/100))\n",
    "cygnss_ds.GLDAS_SoilMoi0_10cm_inst\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b92d7b-7a9f-4684-b907-55835404ddbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subset with the bounding box for desired region\n",
    "\n",
    "- Southern Great Plains: 100-95 W and 32-37 N\n",
    "\n",
    "\n",
    "- Set coordinates to \"latitude\" and \"longitude\" (they're listed as 2D variables in the file)\n",
    "- Clip to bounding box\n",
    "- Result maintains original data array dims, but nans fill the non-desired area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b90cbf40-28b8-492c-94d8-c93b72246815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify your region of interest bounding box\n",
    "min_lon = -100\n",
    "min_lat = 32\n",
    "max_lon = -95\n",
    "max_lat = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e98c250f-f4f0-429c-929e-2fc32ef8085d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reassign coordinates using the latitude and longitude variables\n",
    "cygnss_ds = cygnss_ds.set_coords((\"latitude\", \"longitude\"))\n",
    "\n",
    "# Clip the dataset to the specified bounding box for region of interest\n",
    "cygnss_ds_region = cygnss_ds.where((cygnss_ds.latitude > min_lat) & (cygnss_ds.latitude < max_lat) & (cygnss_ds.longitude > min_lon) & (cygnss_ds.longitude < max_lon))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c00047-11fb-44d3-b518-fb71fb26a3f8",
   "metadata": {},
   "source": [
    "### Check on the interpolation with plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e103c-9525-4908-973d-b68b8ebfabb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot CYGNSS soil moisture\n",
    "#cygnss_ds_region.SM_daily[0,:,:].plot(x=\"longitude\", y=\"latitude\",xlim=(min_lon,max_lon),ylim=(min_lat,max_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3e451-295d-48e0-944c-b87eb27ec088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the regridded NLDAS variable on the CYGNSS grid\n",
    "#interp_ds_region.NLDAS_SoilM_0_10cm[0,:,:].plot(x=\"longitude\", y=\"latitude\",xlim=(min_lon,max_lon),ylim=(min_lat,max_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff8601-46d9-4103-89d3-5678b14a5b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the regridded GLDAS variable on the CYGNSS grid\n",
    "#interp_ds_region.GLDAS_SoilMoi0_10cm_inst[0,:,:].plot(x=\"longitude\", y=\"latitude\",xlim=(min_lon,max_lon),ylim=(min_lat,max_lat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2624dfd-1c4c-4e11-b20a-b44725f9393f",
   "metadata": {},
   "source": [
    "Variable names\n",
    "- NLDAS: NLDAS_SoilM_0_10cm\n",
    "- GLDAS: GLDAS_SoilMoi0_10cm_inst\n",
    "- CYGNSS: SM_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b8c6b-e4cd-4744-b01e-70f4eb10edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Apply CYGNSS masking to interpolated NLDAS/GLDAS\n",
    "\n",
    "# Create a mask of data gaps (where CYGNSS has nans)\n",
    "cygnss_mask = np.isnan(interp_ds_region.SM_daily)\n",
    "\n",
    "# Apply the mask to NLDAS\n",
    "nldas_masked_da = xr.where(cygnss_mask, np.nan, interp_ds_region.NLDAS_SoilM_0_10cm.values)\n",
    "nldas_masked_da = nldas_masked_da.rename('NLDAS_SoilM_0_10cm')\n",
    "\n",
    "# Apply the mask to GLDAS\n",
    "gldas_masked_da = xr.where(cygnss_mask, np.nan, interp_ds_region.GLDAS_SoilMoi0_10cm_inst.values)\n",
    "gldas_masked_da = gldas_masked_da.rename('GLDAS_SoilMoi0_10cm_inst')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408556f2-9460-457f-bc06-1f88d9d9172f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Derive area-averages\n",
    "\n",
    "cygnss_aavg = np.nanmean(interp_ds_region.SM_daily[0,:,:])\n",
    "nldas_aavg = np.nanmean(nldas_masked_da[0,:,:])\n",
    "gldas_aavg = np.nanmean(gldas_masked_da[0,:,:])\n",
    "                        \n",
    "\n",
    "print('CYGNSS Area-Averaged Soil Moisture at SGP:', cygnss_aavg, 'm^3 m-3')\n",
    "print('NLDAS Area-Averaged Soil Moisture at SGP:', nldas_aavg, 'm^3 m-3')\n",
    "print('GLDAS Area-Averaged Soil Moisture at SGP:', gldas_aavg, 'm^3 m-3')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859088a6-611b-42ae-9e7f-17c50822616c",
   "metadata": {},
   "source": [
    "### Re-grid to same spatial resolution\n",
    "\n",
    "Interpolate NLDAS/GLDAS to the CYGNSS grid### Test interpolation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "267de080-52d1-4cb7-87d3-263e6539bc7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Name: interpolate_to_cygnss\n",
    "    \n",
    "    Interpolates a set of points (NLDAS/GLDAS), to another set of points (CYGNSS)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a_pts: np.meshgrid\n",
    "        Meshgrid containing the initial set of lat/lon points\n",
    "        \n",
    "    values: (X, Y) np.ndarray\n",
    "        Array of values to be interpolated \n",
    "       \n",
    "    b_pts: np.meshgrid\n",
    "        Meshgrid containing the final set of lat/lon points that values will be interpolated to\n",
    "        \n",
    "    shape: Tuple\n",
    "        2-D tuple containing the shape of the final interpolated array\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    interp: (X, Y) np.ndarray\n",
    "        Array of final interpolated values\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def interpolate_to_cygnss(a_pts, values, b_pts, shape):\n",
    "    interp = griddata(a_pts, values.values.flatten(), b_pts, method='linear')\n",
    "    interp = interp.reshape(shape)\n",
    "    \n",
    "    return interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c5a20e4-6b0f-4ad5-81d8-6cc7c0869e51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 15.7 s, total: 1min 30s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nx, ny = np.meshgrid(gldas_ds_daily.lon.values, gldas_ds_daily.lat.values)\n",
    "gldas_pts = np.stack([nx.ravel(), ny.ravel()], axis=1)\n",
    "\n",
    "nx, ny = np.meshgrid(nldas_ds_daily.lon.values, nldas_ds_daily.lat.values)\n",
    "nldas_pts = np.stack([nx.ravel(), ny.ravel()], axis=1)\n",
    "\n",
    "cx, cy = cygnss_ds.longitude[0,:,:].values, cygnss_ds.latitude[0,:,:].values\n",
    "cygnss_pts = np.stack([cx.ravel(), cy.ravel()], axis=1)\n",
    "\n",
    "gldas_interp, nldas_interp = [], []\n",
    "\n",
    "#with concurrent.futures.ThreadPoolExecutor(max_workers=12) as executor:\n",
    "#    executor.map(download_granule, range(3))\n",
    "\n",
    "for i in range(3):\n",
    "    gldas_interp.append(interpolate_to_cygnss(gldas_pts,\n",
    "                                                gldas_ds_daily.SoilMoi0_10cm_inst[i,:,:],\n",
    "                                                cygnss_pts,\n",
    "                                                cygnss_ds.SM_daily[0,:,:].shape)\n",
    "                       )\n",
    "    nldas_interp.append(interpolate_to_cygnss(nldas_pts,\n",
    "                                                nldas_ds_daily.SoilM_0_10cm[i,:,:],\n",
    "                                                cygnss_pts,\n",
    "                                                cygnss_ds.SM_daily[0,:,:].shape)\n",
    "                       )\n",
    "    \n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305158b-25ba-4506-b4f1-6a41ad913a24",
   "metadata": {},
   "source": [
    "## Apply CYGNSS masking to interpolated NLDAS/GLDAS\n",
    "\n",
    "Create a mask of data gaps (where CYGNSS has nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "624a0cd2-978e-4ff5-a4f2-ad865b52c6ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a mask of data gaps (where CYGNSS has nans)\n",
    "cygnss_mask = np.isnan(cygnss_ds_region.SM_daily)\n",
    "\n",
    "nldas_masked_da, gldas_masked_da = [], []\n",
    "\n",
    "# Loop through the length of the lists\n",
    "for i in range(3):\n",
    "    # Apply the mask to NLDAS\n",
    "    nldas_masked_values = xr.where(cygnss_mask, np.nan, nldas_interp[i])\n",
    "    nldas_masked_values = nldas_masked_values.rename('NLDAS_SoilM_0_10cm')\n",
    "    nldas_masked_da.append(nldas_masked_values)\n",
    "\n",
    "    # Apply the mask to GLDAS\n",
    "    gldas_masked_values= xr.where(cygnss_mask, np.nan, gldas_interp[i])\n",
    "    gldas_masked_values = gldas_masked_values.rename('GLDAS_SoilMoi0_10cm_inst') \n",
    "    gldas_masked_da.append(gldas_masked_values)\n",
    "    \n",
    "# Concatenate lists of data arrays into a single Xarray dataset\n",
    "nldas_masked_ds = xr.concat(nldas_masked_da, dim=\"time\")\n",
    "gldas_masked_ds = xr.concat(gldas_masked_da, dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa5030-8b31-4f93-bc0a-8b005149f0ee",
   "metadata": {},
   "source": [
    "## Derive area-averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f06b26d0-3c60-49c9-813c-c42d8c9e96cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cygnss_aavgs = []\n",
    "nldas_aavgs = []\n",
    "gldas_aavgs = []\n",
    "\n",
    "for i in range(3):\n",
    "    cygnss_aavgs.append(np.nanmean(cygnss_ds_region.SM_daily[i,:,:]))\n",
    "    nldas_aavgs.append(np.nanmean(nldas_masked_ds[i,:,:].values) / 100)\n",
    "    gldas_aavgs.append(np.nanmean(gldas_masked_ds[i,:,:].values) / 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acce0b0b-92c5-47d3-9af7-55510df712ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18760766, 0.18073194, 0.17513567]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cygnss_aavgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e361cb3a-e9c7-4240-8098-9b218d70e514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2085645107376733, 0.20546505796932837, 0.20656319853245553]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nldas_aavgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8521b20b-b0f2-4cb2-aced-ef9521f448c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19025430993677922, 0.1887662214783532, 0.18954000462657483]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gldas_aavgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211062a7-77d8-4a11-8151-d808fd8b335c",
   "metadata": {},
   "source": [
    "## Plot time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be2901-13b9-40d6-a978-f252a3363024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
