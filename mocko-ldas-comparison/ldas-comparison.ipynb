{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fce52ac-a195-40be-bd21-a34a221e33a2",
   "metadata": {},
   "source": [
    "# LDAS Cloud Use Case\n",
    "\n",
    "## Demonstrate differences in soil moisture between LDAS model output and CYGNSS satellite retrievals in the Earthdata Cloud\n",
    "\n",
    "### Audience\n",
    "Soil moisture researchers who want to see differences between model- and satellite-based products\n",
    "\n",
    "### Goal\n",
    "Compare soil moisture from LDAS (NLDAS, GLDAS models) and CYGNSS (satellite retrieval) in different regions of the world (Southern Great Plains, East Africa) using in-region Earthdata Cloud access.\n",
    "\n",
    "### Assumptions\n",
    "- A variable of interest is identified\n",
    "- Data collections of interest are identified\n",
    "- User has procured access to computing resources in the AWS us-west-2 region\n",
    "\n",
    "### Preconditions\n",
    "- User has access to computing resources in the AWS us-west-2 region\n",
    "- LDAS and CYGNSS data collections are available in the Earthdata Cloud\n",
    "- Identify area(s) of interest for area-averaging\n",
    "    - Southern Great Plains: 100-95 W and 32-37 N\n",
    "    - East Africa: 43-48 E and 5-10 N  \n",
    "\n",
    "<p></p>\n",
    "\n",
    "<div style=\"background:#fc9090;border:1px solid #cccccc;padding:5px 10px;\"><big><b>Note:  </b>Because this notebook uses the S3 protocol, <em><strong>it will only run in an environment with <a href=\"https://disc.gsfc.nasa.gov/information/glossary?keywords=%22earthdata%20cloud%22&amp;title=AWS%20region\">us-west-2 AWS access</a></strong></em>.</big></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37296464-aa82-4451-90e7-056f94eb9577",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook was written using Python 3.8, and requires these libraries and files:\n",
    "- xarray\n",
    "- cartopy\n",
    "- matplotlib\n",
    "- S3FS\n",
    "  - S3FS documentation: (https://s3fs.readthedocs.io/en/latest/install.html)\n",
    "- netrc file with valid Earthdata Login credentials\n",
    "- Approval to access the GES DISC archives with your Earthdata credentials (https://disc.gsfc.nasa.gov/earthdata-login)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dd4602-41a3-48c8-a974-af7e00577b79",
   "metadata": {},
   "source": [
    "## Customize your desired dates range, location, and variables\n",
    "\n",
    "Specify the following pieces of information upfront, then press play to run code!\n",
    "\n",
    "- variables\n",
    "- bounding box\n",
    "- date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b41afc34-bd21-49f8-8ee2-157ab9894162",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify variable names for each dataset\n",
    "nldas_var = \"SoilM_0_10cm\"\n",
    "gldas_var = \"SoilMoi0_10cm_inst\"\n",
    "cygnss_var = \"SM_daily\"\n",
    "\n",
    "# Specify your region of interest bounding box\n",
    "min_lon = -100\n",
    "min_lat = 32\n",
    "max_lon = -95\n",
    "max_lat = 37\n",
    "\n",
    "# Specify start and end time and calculate number of days \n",
    "start_time = '2018-06-01T00:00:00Z'\n",
    "end_time = '2018-07-01T00:00:00Z'\n",
    "\n",
    "from datetime import datetime\n",
    "start_dt = datetime.strptime(start_time, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "end_dt = datetime.strptime(end_time, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "num_days = (end_dt - start_dt).days\n",
    "\n",
    "num_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6955fd-4259-40a4-8154-6f3fd9853f60",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5252bf84-87bd-4940-98ca-c41ec95c3931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from netrc import netrc\n",
    "from subprocess import Popen\n",
    "from platform import system\n",
    "from getpass import getpass\n",
    "import os\n",
    "import requests\n",
    "import xarray as xr\n",
    "import s3fs\n",
    "from scipy.interpolate import griddata\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a66c8-90df-42a5-9da3-841bd0c28ca4",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "\n",
    "Two credentials are required for in-cloud direct S3 access of Earthdata:\n",
    " - Earthdata Login username and password\n",
    " - Temporary S3 access credential for NASA DAAC archives\n",
    "\n",
    "The S3 credential is generated by a lambda function that uses the Earthdata Login credentials provided in your <code>.netrc</code> file to create an access key ID, secret access key, and session token for accessing GES DISC S3 buckets. **This token will only last for one hour**, and if time expires, the kernel will need to be reset and the following cell run again. This notebook also accesses data archived by PO.DAAC. You will also need to generate S3 credentials for PO.DAAC.\n",
    "\n",
    "### STOP: Do you have your Earthdata Login credentials stored in the root directory of this compute system?\n",
    "\n",
    "If no, run the below cell to store your Earthdata username and password in a <code>.netrc</code> file.\n",
    "    \n",
    "If yes, proceed to the next cell.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf0735d-63d8-4340-9138-75d9e525ba59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## You may skip this cell if you have already stored your Earthdata Login credentials\n",
    "\n",
    "urs = 'urs.earthdata.nasa.gov'    # Earthdata URL endpoint for authentication\n",
    "prompts = ['Enter NASA Earthdata Login Username: ',\n",
    "           'Enter NASA Earthdata Login Password: ']\n",
    "\n",
    "netrc_name = \".netrc\"\n",
    "\n",
    "# Determine if netrc file exists, and if so, if it includes NASA Earthdata Login Credentials\n",
    "try:\n",
    "    netrcDir = os.path.expanduser(f\"~/{netrc_name}\")\n",
    "    netrc(netrcDir).authenticators(urs)[0]\n",
    "\n",
    "# Below, create a netrc file and prompt user for NASA Earthdata Login Username and Password\n",
    "except FileNotFoundError:\n",
    "    homeDir = os.path.expanduser(\"~\")\n",
    "    Popen('touch {0}{2} | echo machine {1} >> {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n",
    "    Popen('echo login {} >> {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    Popen('echo \\'password {} \\'>> {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    # Set restrictive permissions\n",
    "    Popen('chmod 0600 {0}{1}'.format(homeDir + os.sep, netrc_name), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b2db32-90c1-46c4-95a8-d8bb0a1ab33c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gesdisc_s3 = \"https://data.gesdisc.earthdata.nasa.gov/s3credentials\"\n",
    "podaac_s3 = \"https://archive.podaac.earthdata.nasa.gov/s3credentials\"\n",
    "\n",
    "# Define a function for S3 access credentials\n",
    "def begin_s3_direct_access(url: str=gesdisc_s3):\n",
    "    response = requests.get(url).json()\n",
    "    return s3fs.S3FileSystem(key=response['accessKeyId'],\n",
    "                             secret=response['secretAccessKey'],\n",
    "                             token=response['sessionToken'],\n",
    "                             client_kwargs={'region_name':'us-west-2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a16cb-bdc1-4a49-b084-54fb3a38a742",
   "metadata": {},
   "source": [
    "## Find Data\n",
    "\n",
    "Use the CMR API to search for the data collections of interest in the desired time range and create a list of S3 URLs that will be accessed. \n",
    "\n",
    "### Date Range\n",
    "\n",
    "- 01 June 2018 - 10 October 2018\n",
    "\n",
    "### Region\n",
    "\n",
    "- Southern Great Plains (100-95 W and 32-37 N)\n",
    "\n",
    "### Data Collections and Variables\n",
    "| Longname    | Shortname | Variable | CMR Concept ID | Time Resolution | Spatial Resolution |\n",
    "| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |\n",
    "| [NLDAS Noah Land Surface Model L4 Hourly 0.125 x 0.125 degree V2.0](https://disc.gsfc.nasa.gov/datasets/NLDAS_NOAH0125_H_2.0/summary?keywords=NLDAS_NOAH0125_H) | NLDAS_NOAH0125_H | SoilM_0_10cm | C2069246977-GES_DISC | Hourly | 0.125 deg |\n",
    "| [GLDAS Noah Land Surface Model L4 3 hourly 0.25 x 0.25 degree V2.1](https://disc.gsfc.nasa.gov/datasets/GLDAS_NOAH025_3H_2.1/summary?keywords=GLDAS_NOAH025_3H_2.1) | GLDAS_NOAH025_3H | SoilMoi0_10cm_inst | C1342986035-GES_DISC | 3-Hourly | 0.25 deg | \n",
    "| [UCAR-CU CYGNSS Level 3 Soil Moisture Version 1.0](https://podaac.jpl.nasa.gov/dataset/CYGNSS_L3_SOIL_MOISTURE_V1.0) | CYGNSS_L3_SOIL_MOISTURE_V1.0 | SM_daily | C2205122332-POCLOUD | Daily | ~0.37 deg lon. by ~0.30 deg lat. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523d74c4-8d01-4165-b194-722913ef01af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function for CMR catalog requests\n",
    "def cmr_request(params):\n",
    "    response = requests.get(url,\n",
    "                        params=params,\n",
    "                        headers={\n",
    "                            'Accept': 'application/json',\n",
    "                        }\n",
    "                       )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce94ada-1746-49ed-9f13-56daf797cbcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://cmr.earthdata.nasa.gov/search/granules'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3c41c-8510-4d4a-9e78-884029db8be4",
   "metadata": {},
   "source": [
    "### NLDAS hourly granules \n",
    "\n",
    "Use the table above to fill in the concept ID for the NLDAS data collection in the CMR API call. Create a list of S3 URLs based on the CMR response for your search. \n",
    "\n",
    "Estimate the number of granules you expect to find based on the time resolution and time range and adjust the page size accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494275f0-7f16-438f-b6e5-43777b694140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nldas_concept_id = 'C2069246977-GES_DISC'\n",
    "page_size = 24*30+1\n",
    "response = cmr_request({\n",
    "                        'concept_id': nldas_concept_id,\n",
    "                        'temporal': start_time+','+end_time,\n",
    "                        'page_size': page_size\n",
    "                        })\n",
    "nldas_granules = response.json()['feed']['entry']\n",
    "\n",
    "nldas_s3_urls = []\n",
    "for granule in nldas_granules:\n",
    "    nldas_s3_urls.append(next((item['href'] for item in granule['links'] if item[\"href\"].startswith(\"s3://\")), None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec1ab7d-5995-43fd-a420-924a2aacd2df",
   "metadata": {},
   "source": [
    "### GLDAS 3-hourly granules \n",
    "\n",
    "Use the table above to fill in the concept ID for the GLDAS data collection in the CMR API call. Create a list of S3 URLs based on the CMR response for your search. \n",
    "\n",
    "Estimate the number of granules you expect to find based on the time resolution and time range and adjust the page size accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d0d69e-9774-42fe-9b5c-6da3f46073ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gldas_concept_id = 'C1342986035-GES_DISC'\n",
    "page_size = 8*30+1\n",
    "response = cmr_request({\n",
    "                        'concept_id': gldas_concept_id,\n",
    "                        'temporal': start_time+','+end_time,\n",
    "                        'page_size': page_size\n",
    "                        })\n",
    "gldas_granules = response.json()['feed']['entry']\n",
    "\n",
    "gldas_s3_urls = []\n",
    "for granule in gldas_granules:\n",
    "    gldas_s3_urls.append(next((item['href'] for item in granule['links'] if item[\"href\"].startswith(\"s3://\")), None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93260cf1-85ff-4ec4-b7b4-c04d04245da2",
   "metadata": {},
   "source": [
    "### CYGNSS daily granules \n",
    "\n",
    "Use the table above to fill in the concept ID for the CYGNSS data collection in the CMR API call. Create a list of S3 URLs based on the CMR response for your search. \n",
    "\n",
    "Estimate the number of granules you expect to find based on the time resolution and time range and adjust the page size accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5099777f-8314-4b8c-9e24-22db9ae55588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cygnss_concept_id = 'C2205122332-POCLOUD'\n",
    "page_size = 31\n",
    "response = cmr_request({\n",
    "                        'concept_id': cygnss_concept_id,\n",
    "                        'temporal': start_time+','+end_time,\n",
    "                        'page_size': page_size\n",
    "                        })\n",
    "cygnss_granules = response.json()['feed']['entry']\n",
    "\n",
    "cygnss_s3_urls = []\n",
    "for granule in cygnss_granules:\n",
    "    cygnss_s3_urls.append(next((item['href'] for item in granule['links'] if item[\"href\"].startswith(\"s3://\") and item[\"href\"].endswith(\".nc\")), None)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c6225-12bd-412e-8907-270b2b74da9c",
   "metadata": {},
   "source": [
    "## Access Data\n",
    "\n",
    "### Begin S3FS sessions\n",
    "\n",
    "Begin your S3FS session that you set up earlier in the \"Credentials\" section.\n",
    "\n",
    "Remember, these S3FS sessions are specific to the DAAC-owned S3 buckets, so we will create a session for each DAAC we are accessing data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33e134ff-975f-4bbf-bac9-1dda1b9e1623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(s3fs.core.S3FileSystem, s3fs.core.S3FileSystem)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_gesdisc = begin_s3_direct_access(gesdisc_s3)\n",
    "fs_podaac = begin_s3_direct_access(podaac_s3)\n",
    "\n",
    "# Check that the file system is intact as an S3FileSystem object, which means that token is valid\n",
    "# Common causes of rejected S3 access tokens include incorrect passwords stored in the netrc file, or a non-existent netrc file\n",
    "type(fs_gesdisc), type(fs_podaac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6556eb2-31d9-4377-9292-ab4ea547bdc8",
   "metadata": {},
   "source": [
    "### Open granules using xarray\n",
    "\n",
    "We will use the xarray Python library to read and open the files we found using the CMR API and put into lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a844aa47-443d-48b8-ba6b-282308c6f68c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 2s, sys: 57 s, total: 8min 59s\n",
      "Wall time: 21min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nldas_ds = xr.open_mfdataset(\n",
    "    paths=[fs_gesdisc.open(f) for f in nldas_s3_urls[0:num_days*24]],\n",
    "    combine='by_coords',\n",
    "    decode_cf=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd12dd9f-4273-4cc0-98df-fdd98d42dbab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 28s, sys: 1.87 s, total: 3min 30s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gldas_ds = xr.open_mfdataset(\n",
    "    paths=[fs_gesdisc.open(f) for f in gldas_s3_urls[0:num_days*8]],\n",
    "    combine='by_coords',\n",
    "    mask_and_scale=True,\n",
    "    decode_cf=True,\n",
    "    parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a36180e5-da90-4a95-a590-697e9d298ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 2.59 s, total: 13.5 s\n",
      "Wall time: 47.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cygnss_ds = xr.open_mfdataset(\n",
    "    paths=[fs_podaac.open(f) for f in cygnss_s3_urls[0:num_days]],\n",
    "    combine='by_coords',\n",
    "    mask_and_scale=True,\n",
    "    decode_cf=True,\n",
    "    parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae1439-4d88-4132-9d0f-f296b6d40cbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process Data\n",
    "\n",
    "- Match temporal resolution\n",
    "- Re-grid/interpolate to same spatial resolution\n",
    "- Create new dataset with interpolated variables\n",
    "    - Ensure same units\n",
    "- Subset with the bounding box for desired region\n",
    "- Remove the data gaps using a mask for CYGNSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeadaad-5975-4be5-af39-1d9f8cad91bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Match temporal resolution\n",
    "Resample NLDAS and GLDAS to daily time resolution to match CYGNSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "042cac3f-e04b-4883-9856-1f5fd2b29828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nldas_ds_daily = nldas_ds.resample(time=\"1D\").mean()\n",
    "gldas_ds_daily = gldas_ds.resample(time=\"1D\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be6aa3-9528-44c0-8079-75766b781680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### Re-grid to same spatial resolution\n",
    "\n",
    "Interpolate NLDAS/GLDAS to the CYGNSS grid\n",
    "\n",
    "%%time\n",
    "# NLDAS --> CYGNSS interpolation\n",
    "nx, ny = np.meshgrid(nldas_ds_daily.lon.values, nldas_ds_daily.lat.values)\n",
    "nldas_pts = np.stack([nx.ravel(), ny.ravel()], axis=1)\n",
    "\n",
    "cx, cy = cygnss_ds.longitude[0,:,:].values, cygnss_ds.latitude[0,:,:].values\n",
    "cygnss_pts = np.stack([cx.ravel(), cy.ravel()], axis=1)\n",
    "\n",
    "nldas_sm_interp = griddata(nldas_pts, nldas_ds_daily.SoilM_0_10cm.isel(time=0).values.flatten(), cygnss_pts, method='linear')\n",
    "\n",
    "nldas_sm_interp = nldas_sm_interp.reshape(252, 802)\n",
    "nldas_sm_interp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183f6c8-74e1-4470-9873-c37ac888a645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "# GLDAS --> CYGNSS interpolation\n",
    "nx, ny = np.meshgrid(gldas_ds_daily.lon.values, gldas_ds_daily.lat.values)\n",
    "gldas_pts = np.stack([nx.ravel(), ny.ravel()], axis=1)\n",
    "\n",
    "cx, cy = cygnss_ds.longitude.values, cygnss_ds.latitude.values\n",
    "cygnss_pts = np.stack([cx.ravel(), cy.ravel()], axis=1)\n",
    "\n",
    "gldas_sm_interp = griddata(gldas_pts, gldas_ds_daily.SoilMoi0_10cm_inst[0,:,:].values.flatten(), cygnss_pts, method='linear')\n",
    "\n",
    "gldas_sm_interp = gldas_sm_interp.reshape(1, 252, 802)\n",
    "#gldas_sm_interp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cfe652-6b1a-49d7-b0e8-11b34f7d860d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Add interpolated variables to a new dataset\n",
    "\n",
    "Add interpolated variables to CYGNSS dataset and convert units\n",
    "\n",
    "\n",
    "Divide NLDAS and GLDAS by 100.0 to convert from [kg m-2] to [m^3 m-3].\n",
    "\n",
    "\n",
    "CYGNSS is in [cm^3 cm-3], which is identical to [m^3 m-3].\n",
    "\n",
    "cygnss_ds = cygnss_ds.assign(NLDAS_SoilM_0_10cm=([\"time\", \"lat\", \"lon\"], nldas_sm_interp/100))\n",
    "cygnss_ds.NLDAS_SoilM_0_10cm\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94683886-19b3-4ed0-85cd-5e04b5b0eec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cygnss_ds = cygnss_ds.assign(GLDAS_SoilMoi0_10cm_inst=([\"time\", \"lat\", \"lon\"], gldas_sm_interp/100))\n",
    "cygnss_ds.GLDAS_SoilMoi0_10cm_inst\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b92d7b-7a9f-4684-b907-55835404ddbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subset with the bounding box for desired region\n",
    "\n",
    "- Southern Great Plains: 100-95 W and 32-37 N\n",
    "\n",
    "\n",
    "- Set coordinates to \"latitude\" and \"longitude\" (they're listed as 2D variables in the file)\n",
    "- Clip to bounding box\n",
    "- Result maintains original data array dims, but nans fill the non-desired area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e98c250f-f4f0-429c-929e-2fc32ef8085d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 252, 802)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reassign coordinates using the latitude and longitude variables\n",
    "cygnss_ds = cygnss_ds.set_coords((\"latitude\", \"longitude\"))\n",
    "\n",
    "# Clip the dataset to the specified bounding box for region of interest\n",
    "cygnss_ds_region = cygnss_ds.where((cygnss_ds.latitude > min_lat) & (cygnss_ds.latitude < max_lat) & (cygnss_ds.longitude > min_lon) & (cygnss_ds.longitude < max_lon))\n",
    "\n",
    "#cygnss_ds_region.SM_daily.values.shape\n",
    "cygnss_ds_region[cygnss_var].values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c00047-11fb-44d3-b518-fb71fb26a3f8",
   "metadata": {},
   "source": [
    "### Check on the interpolation with plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e103c-9525-4908-973d-b68b8ebfabb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot CYGNSS soil moisture\n",
    "#cygnss_ds_region.SM_daily[0,:,:].plot(x=\"longitude\", y=\"latitude\",xlim=(min_lon,max_lon),ylim=(min_lat,max_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3e451-295d-48e0-944c-b87eb27ec088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the regridded NLDAS variable on the CYGNSS grid\n",
    "#interp_ds_region.NLDAS_SoilM_0_10cm[0,:,:].plot(x=\"longitude\", y=\"latitude\",xlim=(min_lon,max_lon),ylim=(min_lat,max_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff8601-46d9-4103-89d3-5678b14a5b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the regridded GLDAS variable on the CYGNSS grid\n",
    "#interp_ds_region.GLDAS_SoilMoi0_10cm_inst[0,:,:].plot(x=\"longitude\", y=\"latitude\",xlim=(min_lon,max_lon),ylim=(min_lat,max_lat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2624dfd-1c4c-4e11-b20a-b44725f9393f",
   "metadata": {},
   "source": [
    "Variable names\n",
    "- NLDAS: NLDAS_SoilM_0_10cm\n",
    "- GLDAS: GLDAS_SoilMoi0_10cm_inst\n",
    "- CYGNSS: SM_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b8c6b-e4cd-4744-b01e-70f4eb10edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Apply CYGNSS masking to interpolated NLDAS/GLDAS\n",
    "\n",
    "# Create a mask of data gaps (where CYGNSS has nans)\n",
    "cygnss_mask = np.isnan(interp_ds_region.SM_daily)\n",
    "\n",
    "# Apply the mask to NLDAS\n",
    "nldas_masked_da = xr.where(cygnss_mask, np.nan, interp_ds_region.NLDAS_SoilM_0_10cm.values)\n",
    "nldas_masked_da = nldas_masked_da.rename('NLDAS_SoilM_0_10cm')\n",
    "\n",
    "# Apply the mask to GLDAS\n",
    "gldas_masked_da = xr.where(cygnss_mask, np.nan, interp_ds_region.GLDAS_SoilMoi0_10cm_inst.values)\n",
    "gldas_masked_da = gldas_masked_da.rename('GLDAS_SoilMoi0_10cm_inst')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408556f2-9460-457f-bc06-1f88d9d9172f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Derive area-averages\n",
    "\n",
    "cygnss_aavg = np.nanmean(interp_ds_region.SM_daily[0,:,:])\n",
    "nldas_aavg = np.nanmean(nldas_masked_da[0,:,:])\n",
    "gldas_aavg = np.nanmean(gldas_masked_da[0,:,:])\n",
    "                        \n",
    "\n",
    "print('CYGNSS Area-Averaged Soil Moisture at SGP:', cygnss_aavg, 'm^3 m-3')\n",
    "print('NLDAS Area-Averaged Soil Moisture at SGP:', nldas_aavg, 'm^3 m-3')\n",
    "print('GLDAS Area-Averaged Soil Moisture at SGP:', gldas_aavg, 'm^3 m-3')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859088a6-611b-42ae-9e7f-17c50822616c",
   "metadata": {},
   "source": [
    "### Re-grid to same spatial resolution\n",
    "\n",
    "Interpolate NLDAS/GLDAS to the CYGNSS grid### Test interpolation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "267de080-52d1-4cb7-87d3-263e6539bc7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Name: interpolate_to_cygnss\n",
    "    \n",
    "    Interpolates a set of points (NLDAS/GLDAS), to another set of points (CYGNSS)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a_pts: np.meshgrid\n",
    "        Meshgrid containing the initial set of lat/lon points\n",
    "        \n",
    "    values: (X, Y) np.ndarray\n",
    "        Array of values to be interpolated \n",
    "       \n",
    "    b_pts: np.meshgrid\n",
    "        Meshgrid containing the final set of lat/lon points that values will be interpolated to\n",
    "        \n",
    "    shape: Tuple\n",
    "        2-D tuple containing the shape of the final interpolated array\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    interp: (X, Y) np.ndarray\n",
    "        Array of final interpolated values\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def interpolate_to_cygnss(a_pts, values, b_pts, shape):\n",
    "    interp = griddata(a_pts, values.values.flatten(), b_pts, method='linear')\n",
    "    interp = interp.reshape(shape)\n",
    "    \n",
    "    return interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c5a20e4-6b0f-4ad5-81d8-6cc7c0869e51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 8s, sys: 3min 18s, total: 19min 26s\n",
      "Wall time: 25min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nx, ny = np.meshgrid(gldas_ds_daily.lon.values, gldas_ds_daily.lat.values)\n",
    "gldas_pts = np.stack([nx.ravel(), ny.ravel()], axis=1)\n",
    "\n",
    "nx, ny = np.meshgrid(nldas_ds_daily.lon.values, nldas_ds_daily.lat.values)\n",
    "nldas_pts = np.stack([nx.ravel(), ny.ravel()], axis=1)\n",
    "\n",
    "cx, cy = cygnss_ds.longitude[0,:,:].values, cygnss_ds.latitude[0,:,:].values\n",
    "cygnss_pts = np.stack([cx.ravel(), cy.ravel()], axis=1)\n",
    "\n",
    "gldas_interp, nldas_interp = [], []\n",
    "\n",
    "#with concurrent.futures.ThreadPoolExecutor(max_workers=12) as executor:\n",
    "#    executor.map(download_granule, range(3))\n",
    "\n",
    "for i in range(num_days):\n",
    "    gldas_interp.append(interpolate_to_cygnss(gldas_pts,\n",
    "                                                #gldas_ds_daily.SoilMoi0_10cm_inst[i,:,:],\n",
    "                                                gldas_ds_daily[gldas_var][i,:,:],\n",
    "                                                cygnss_pts,\n",
    "                                                cygnss_ds[cygnss_var][0,:,:].shape)\n",
    "                       )\n",
    "    nldas_interp.append(interpolate_to_cygnss(nldas_pts,\n",
    "                                                #nldas_ds_daily.SoilM_0_10cm[i,:,:],\n",
    "                                                nldas_ds_daily[nldas_var][i,:,:],\n",
    "                                                cygnss_pts,\n",
    "                                                cygnss_ds[cygnss_var][0,:,:].shape)\n",
    "                       )\n",
    "    \n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305158b-25ba-4506-b4f1-6a41ad913a24",
   "metadata": {},
   "source": [
    "## Apply CYGNSS masking to interpolated NLDAS/GLDAS\n",
    "\n",
    "Create a mask of data gaps (where CYGNSS has nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "624a0cd2-978e-4ff5-a4f2-ad865b52c6ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "The provided token has expired.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/s3fs/core.py:112\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3_RETRYABLE_ERRORS \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/aiobotocore/client.py:358\u001b[0m, in \u001b[0;36mAioBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    357\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ExpiredToken) when calling the GetObject operation: The provided token has expired.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     gldas_masked_da\u001b[38;5;241m.\u001b[39mappend(gldas_masked_values)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Concatenate lists of data arrays into a single Xarray dataset\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m nldas_masked_ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnldas_masked_da\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m gldas_masked_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mconcat(gldas_masked_da, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/concat.py:237\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompat=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompat\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m invalid: must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbroadcast_equals\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequals\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_conflicts\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverride\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m     )\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_obj, DataArray):\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dataarray_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_obj, Dataset):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _dataset_concat(\n\u001b[1;32m    250\u001b[0m         objs,\n\u001b[1;32m    251\u001b[0m         dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    259\u001b[0m     )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/concat.py:702\u001b[0m, in \u001b[0;36m_dataarray_concat\u001b[0;34m(arrays, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    699\u001b[0m             arr \u001b[38;5;241m=\u001b[39m cast(T_DataArray, arr\u001b[38;5;241m.\u001b[39mrename(name))\n\u001b[1;32m    700\u001b[0m     datasets\u001b[38;5;241m.\u001b[39mappend(arr\u001b[38;5;241m.\u001b[39m_to_temp_dataset())\n\u001b[0;32m--> 702\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43m_dataset_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m merged_attrs \u001b[38;5;241m=\u001b[39m merge_attrs([da\u001b[38;5;241m.\u001b[39mattrs \u001b[38;5;28;01mfor\u001b[39;00m da \u001b[38;5;129;01min\u001b[39;00m arrays], combine_attrs)\n\u001b[1;32m    716\u001b[0m result \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds, name)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/concat.py:505\u001b[0m, in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m [cast(T_Dataset, ds\u001b[38;5;241m.\u001b[39mexpand_dims(dim)) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# determine which variables to concatenate\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m concat_over, equals, concat_dim_lengths \u001b[38;5;241m=\u001b[39m \u001b[43m_calc_concat_over\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# determine which variables to merge, and then merge them according to compat\u001b[39;00m\n\u001b[1;32m    510\u001b[0m variables_to_merge \u001b[38;5;241m=\u001b[39m (coord_names \u001b[38;5;241m|\u001b[39m data_names) \u001b[38;5;241m-\u001b[39m concat_over \u001b[38;5;241m-\u001b[39m unlabeled_dims\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/concat.py:406\u001b[0m, in \u001b[0;36m_calc_concat_over\u001b[0;34m(datasets, dim, dim_names, data_vars, coords, compat)\u001b[0m\n\u001b[1;32m    403\u001b[0m         concat_over\u001b[38;5;241m.\u001b[39mupdate(opt)\n\u001b[1;32m    405\u001b[0m process_subset_opt(data_vars, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_vars\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 406\u001b[0m \u001b[43mprocess_subset_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat_over, equals, concat_dim_lengths\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/concat.py:363\u001b[0m, in \u001b[0;36m_calc_concat_over.<locals>.process_subset_opt\u001b[0;34m(opt, subset)\u001b[0m\n\u001b[1;32m    356\u001b[0m     concat_over\u001b[38;5;241m.\u001b[39madd(k)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m equals[k] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Compare the variable of all datasets vs. the one\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# of the first dataset. Perform the minimum amount of\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# loads in order to avoid multiple loads from disk\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# while keeping the RAM footprint low.\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     v_lhs \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# We'll need to know later on if variables are equal.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     computed \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/variable.py:530\u001b[0m, in \u001b[0;36mVariable.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this variable's data from disk or a\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03mremote source into memory and return this variable.\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03mdask.array.compute\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_duck_dask_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data):\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m as_compatible_data(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_duck_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data):\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/base.py:314\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/base.py:599\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    597\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 599\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/array/core.py:125\u001b[0m, in \u001b[0;36mgetter\u001b[0;34m(a, b, asarray, lock)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# Below we special-case `np.matrix` to force a conversion to\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `np.ndarray` and preserve original Dask behavior for `getter`,\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# as for all purposes `np.matrix` is array-like and thus\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# `is_arraylike` evaluates to `True` in that case.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m asarray \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_arraylike(c) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, np\u001b[38;5;241m.\u001b[39mmatrix)):\n\u001b[0;32m--> 125\u001b[0m         c \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:459\u001b[0m, in \u001b[0;36mImplicitToExplicitIndexingAdapter.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:623\u001b[0m, in \u001b[0;36mCopyOnWriteArray.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:524\u001b[0m, in \u001b[0;36mLazilyIndexedArray.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    523\u001b[0m     array \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray)\n\u001b[0;32m--> 524\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/h5netcdf_.py:43\u001b[0m, in \u001b[0;36mH5NetCDFArrayWrapper.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplicit_indexing_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexingSupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOUTER_1VECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:815\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    814\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m--> 815\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mraw_indexing_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n\u001b[1;32m    818\u001b[0m     result \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(np\u001b[38;5;241m.\u001b[39masarray(result))[numpy_indices]\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/h5netcdf_.py:49\u001b[0m, in \u001b[0;36mH5NetCDFArrayWrapper._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mlock:\n\u001b[0;32m---> 49\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m array[key]\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/h5netcdf_.py:39\u001b[0m, in \u001b[0;36mH5NetCDFArrayWrapper.get_array\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 39\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatastore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mvariables[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable_name]\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/h5netcdf_.py:172\u001b[0m, in \u001b[0;36mH5NetCDFStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    173\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(\n\u001b[1;32m    174\u001b[0m             root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode, create_group\u001b[38;5;241m=\u001b[39m_h5netcdf_create_group\n\u001b[1;32m    175\u001b[0m         )\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/file_manager.py:198\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/file_manager.py:216\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    214\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    215\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 216\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/h5netcdf/core.py:1064\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, path, mode, invalid_netcdf, phony_dims, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preexisting_file \u001b[38;5;241m=\u001b[39m mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   1063\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h5py \u001b[38;5;241m=\u001b[39m h5py\n\u001b[0;32m-> 1064\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h5file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_h5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/h5py/_hl/files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    230\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 231\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    233\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5fd.pyx:163\u001b[0m, in \u001b[0;36mh5py.h5fd.H5FD_fileobj_read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/fsspec/spec.py:1694\u001b[0m, in \u001b[0;36mAbstractBufferedFile.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"mirrors builtin file's readinto method\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03mhttps://docs.python.org/3/library/io.html#io.RawIOBase.readinto\u001b[39;00m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1694\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnbytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m out[: \u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/fsspec/spec.py:1684\u001b[0m, in \u001b[0;36mAbstractBufferedFile.read\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m   1681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1682\u001b[0m     \u001b[38;5;66;03m# don't even bother calling fetch\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1684\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(out)\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/fsspec/caching.py:154\u001b[0m, in \u001b[0;36mReadAheadCache._fetch\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    152\u001b[0m     part \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, end \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize)\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# new block replaces old\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m=\u001b[39m start\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/s3fs/core.py:2143\u001b[0m, in \u001b[0;36mS3File._fetch_range\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m   2141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetch_range\u001b[39m(\u001b[38;5;28mself\u001b[39m, start, end):\n\u001b[1;32m   2142\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fetch_range\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2144\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2145\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2147\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2148\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2149\u001b[0m \u001b[43m            \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreq_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreq_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2151\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2153\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m   2154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ex\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mEINVAL \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre-conditions\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ex\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/s3fs/core.py:2286\u001b[0m, in \u001b[0;36m_fetch_range\u001b[0;34m(fs, bucket, key, version_id, start, end, req_kw)\u001b[0m\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2285\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetch: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, bucket, key, start, end)\n\u001b[0;32m-> 2286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_inner_fetch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/fsspec/asyn.py:99\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/fsspec/asyn.py:54\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     52\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/s3fs/core.py:2290\u001b[0m, in \u001b[0;36m_inner_fetch\u001b[0;34m(fs, bucket, key, version_id, start, end, req_kw)\u001b[0m\n\u001b[1;32m   2289\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inner_fetch\u001b[39m(fs, bucket, key, version_id, start, end, req_kw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 2290\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fs\u001b[38;5;241m.\u001b[39m_call_s3(\n\u001b[1;32m   2291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2292\u001b[0m         Bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[1;32m   2293\u001b[0m         Key\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m   2294\u001b[0m         Range\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes=\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (start, end \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   2295\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mversion_id_kw(version_id),\n\u001b[1;32m   2296\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreq_kw,\n\u001b[1;32m   2297\u001b[0m     )\n\u001b[1;32m   2298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/s3fs/core.py:339\u001b[0m, in \u001b[0;36mS3FileSystem._call_s3\u001b[0;34m(self, method, *akwarglist, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCALL: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, akwarglist, kw2)\n\u001b[1;32m    338\u001b[0m additional_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_s3_method_kwargs(method, \u001b[38;5;241m*\u001b[39makwarglist, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _error_wrapper(\n\u001b[1;32m    340\u001b[0m     method, kwargs\u001b[38;5;241m=\u001b[39madditional_kwargs, retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries\n\u001b[1;32m    341\u001b[0m )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/s3fs/core.py:139\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    137\u001b[0m         err \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m    138\u001b[0m err \u001b[38;5;241m=\u001b[39m translate_boto_error(err)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[0;31mPermissionError\u001b[0m: The provided token has expired."
     ]
    }
   ],
   "source": [
    "# Create a mask of data gaps (where CYGNSS has nans)\n",
    "cygnss_mask = np.isnan(cygnss_ds_region.SM_daily)\n",
    "\n",
    "nldas_masked_da, gldas_masked_da = [], []\n",
    "\n",
    "# Loop through the length of the lists\n",
    "for i in range(3):\n",
    "    # Apply the mask to NLDAS\n",
    "    nldas_masked_values = xr.where(cygnss_mask[i,:,:], np.nan, nldas_interp[i])\n",
    "    #nldas_masked_values = nldas_masked_values.rename('NLDAS_SoilM_0_10cm')\n",
    "    nldas_masked_values = nldas_masked_values.rename('NLDAS_'+nldas_var)\n",
    "    nldas_masked_da.append(nldas_masked_values)\n",
    "\n",
    "    # Apply the mask to GLDAS\n",
    "    gldas_masked_values= xr.where(cygnss_mask[i,:,:], np.nan, gldas_interp[i])\n",
    "    gldas_masked_values = gldas_masked_values.rename('GLDAS_'+gldas_var) \n",
    "    gldas_masked_da.append(gldas_masked_values)\n",
    "    \n",
    "# Concatenate lists of data arrays into a single Xarray dataset\n",
    "nldas_masked_ds = xr.concat(nldas_masked_da, dim=\"time\")\n",
    "gldas_masked_ds = xr.concat(gldas_masked_da, dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa5030-8b31-4f93-bc0a-8b005149f0ee",
   "metadata": {},
   "source": [
    "## Derive area-averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b26d0-3c60-49c9-813c-c42d8c9e96cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cygnss_aavgs = []\n",
    "nldas_aavgs = []\n",
    "gldas_aavgs = []\n",
    "\n",
    "for i in range(3):\n",
    "    cygnss_aavgs.append(np.nanmean(cygnss_ds_region[cygnss_var][i,:,:]))\n",
    "    nldas_aavgs.append(np.nanmean(nldas_masked_ds[i,:,:].values) / 100)\n",
    "    gldas_aavgs.append(np.nanmean(gldas_masked_ds[i,:,:].values) / 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce0b0b-92c5-47d3-9af7-55510df712ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cygnss_aavgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e361cb3a-e9c7-4240-8098-9b218d70e514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nldas_aavgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521b20b-b0f2-4cb2-aced-ef9521f448c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gldas_aavgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211062a7-77d8-4a11-8151-d808fd8b335c",
   "metadata": {},
   "source": [
    "## Plot time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be2901-13b9-40d6-a978-f252a3363024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Figure size\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "\n",
    "# Figure setup\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cygnss_aavgs, label='CYGNSS', marker=\".\")\n",
    "ax.plot(nldas_aavgs, label='NLDAS', marker=\".\")\n",
    "ax.plot(gldas_aavgs, label='GLDAS', marker=\".\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1120e5d-ed90-42fc-9a24-fa030a46b5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
